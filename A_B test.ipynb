{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Test\n",
    "\n",
    "## Project Description\n",
    "You've received an analytical task from an international online store. Your predecessor failed to complete it: they launched an A/B test and then quit. They left only the technical specifications and the test results.\n",
    "\n",
    "## Technical description\n",
    "* Test name: recommender_system_test\n",
    "* Groups: А (control), B (new payment funnel)\n",
    "* Launch date: 2020-12-07\n",
    "* The date when they stopped taking up new users: 2020-12-21\n",
    "* End date: 2021-01-01\n",
    "* Audience: 15% of the new users from the EU region\n",
    "* Purpose of the test: testing changes related to the introduction of an improved recommendation system\n",
    "* Expected result: within 14 days of signing up, users will show better conversion into product page views (the product_page event), product card views (product_card) and purchases (purchase). At each of the stage of the funnel product_page → product_card → purchase, there will be at least a 10% increase.\n",
    "* Expected number of test participants: 6000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Analyze Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import math\n",
    "from scipy import stats as st\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly import graph_objects as go\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datasets/ab_project_marketing_events_us.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# load files\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m marketing_events \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/datasets/ab_project_marketing_events_us.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstart_dt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinish_dt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m new_users \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/datasets/final_ab_new_users_upd_us.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, parse_dates \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_date\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m events \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/datasets/final_ab_events_upd_us.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, parse_dates \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_dt\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datasets/ab_project_marketing_events_us.csv'"
     ]
    }
   ],
   "source": [
    "# load files\n",
    "marketing_events = pd.read_csv('/datasets/ab_project_marketing_events_us.csv', parse_dates = ['start_dt', 'finish_dt'])\n",
    "new_users = pd.read_csv('/datasets/final_ab_new_users_upd_us.csv', parse_dates = ['first_date'])\n",
    "events = pd.read_csv('/datasets/final_ab_events_upd_us.csv', parse_dates = ['event_dt'])\n",
    "participants = pd.read_csv('/datasets/final_ab_participants_upd_us.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files =  [marketing_events, new_users, events, participants]\n",
    "for file in files:\n",
    "    display(file.head())\n",
    "    display(file.info())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We had already y changed the data type for all date columns to datetime. We did that for marketing_events, new_users, and events tables. So, first, we will check for ducplicate rows in all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.duplicated().sum()\n",
    "for file in files:\n",
    "    display(file.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicate rows.  From the previous step, we can see that values are missing in the details column in the events table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.groupby['events_name']('details').unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than 'purcharse', we don't have information for the other events. Nothing seems wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing descriptive info for 'new users' and 'events'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(new_users)['first_date'].describe()\n",
    "events['events_dt'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are new users later than the specified date of 2020-12-21, up to 2020-12-23. We can see that the last event date is 2020-12-30, compared to the specified date - 2021-01-01. Let's take a look on the ab_test values from participants table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants['ab_test'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's two tests. Since we need to study 'interface_eu_test', we'll drop the drop participants of the 'recommender_system_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "participants = participants[participants['ab_test'] == 'interface_eu_test']\n",
    "\n",
    "# Drop the 'ab_test' column as it's no longer needed\n",
    "participants = participants.drop(columns=['ab_test'])\n",
    "\n",
    "\n",
    "print(\"\\nFiltered participants DataFrame:\")\n",
    "participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying if we have users in both groups as well as the amount of participants for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by user_id and count unique groups\n",
    "grouped = participants.groupby('user_id')['group'].nunique()\n",
    "\n",
    "#Filter users who are in more than one group\n",
    "filtered = grouped[grouped > 1]\n",
    "\n",
    "#Get the number of such users\n",
    "num_users_in_multiple_groups = len(filtered)\n",
    "\n",
    "num_users_in_multiple_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no users assigned to both groups. We have similar number of participants in both group, and in total much more than the 6000 required. Now We'll merge the dataframes to one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = events.merge (paprticipants, on = 'user_id', how = 'inner')\n",
    "final_df = final_df.merge(new_users, on='user_id', how='inner')\n",
    "final_df.head()\n",
    "final_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby('group')['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the logs to see which events occurred and how often they occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['event_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate  the number of unique users who performed each event and the proportion of these users relative to the total number of unique users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_funnel = final_df.groupby('event_name')['user_id'].nunique().reset_index()\n",
    "events_funnel.columns = ['events', 'users']\n",
    "total_users = final_df['user_id'].nunique()\n",
    "events_funnel['share_%'] =  (events_funnel['users'] / total_users * 100).round(2)\n",
    "events_funnel = events_funnel.sort_values(by='users', ascending=False).reset_index(drop=True)\n",
    "events_funnel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the technical description, the event funnel is login > product page > product_cart (optional) > purchase. We'll need to change the order of purchase and product_cart and get the visual funnel without the product_cart event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_funnel = events_funnel.set_index(pd.Index([0, 1, 3, 2]))\n",
    "events_funnel.sort_index(inplace=True)\n",
    "events_funnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(go.Funnel(\n",
    "    y = events_funnel['event'],\n",
    "    x = events_funnel['users'], textinfo = \"value+percent previous\"))\n",
    "fig.update_layout(title='Sales funnel for experimental groups')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m funnel_data\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Assuming final_df is already defined\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Create funnel data for all groups\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m events_funnel \u001b[38;5;241m=\u001b[39m create_funnel_data(\u001b[43mfinal_df\u001b[49m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Create funnel data for group A\u001b[39;00m\n\u001b[0;32m     22\u001b[0m events_funnel_a \u001b[38;5;241m=\u001b[39m create_funnel_data(final_df, group\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def create_funnel_data(df, group=None):\n",
    "    if group:\n",
    "        df = df[df['group'] == group]\n",
    "    funnel_data = df.groupby('event_name')['user_id'].nunique().reset_index()\n",
    "    funnel_data.columns = ['events', 'users']\n",
    "    total_users = df['user_id'].nunique()\n",
    "    funnel_data['share_%'] = (funnel_data['users'] / total_users * 100).round(2)\n",
    "\n",
    "    if len(funnel_data) >= 4:\n",
    "        funnel_data = funnel_data.set_index(pd.Index([0, 1, 3, 2]))\n",
    "        funnel_data.sort_index(inplace=True)\n",
    "    else:\n",
    "        funnel_data = funnel_data.reset_index(drop=True)\n",
    "\n",
    "    return funnel_data\n",
    "\n",
    "# Assuming final_df is already defined\n",
    "# Create funnel data for all groups\n",
    "events_funnel = create_funnel_data(final_df)\n",
    "\n",
    "# Create funnel data for group A\n",
    "events_funnel_a = create_funnel_data(final_df, group='A')\n",
    "\n",
    "# Create funnel data for group B\n",
    "events_funnel_b = create_funnel_data(final_df, group='B')\n",
    "\n",
    "# Display the funnel data for group A and B to verify\n",
    "print(events_funnel_a)\n",
    "print(events_funnel_b)\n",
    "\n",
    "# Plot the funnel for both groups\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Funnel(\n",
    "    name='Group A',\n",
    "    y=events_funnel_a['events'],\n",
    "    x=events_funnel_a['users'], \n",
    "    textinfo=\"value+percent previous\"))\n",
    "fig.add_trace(go.Funnel(\n",
    "    name='Group B',\n",
    "    y=events_funnel_b['events'],\n",
    "    x=events_funnel_b['users'], \n",
    "    textinfo=\"value+percent previous\"))\n",
    "\n",
    "fig.update_layout(title='Sales funnel for experimental groups')\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMMENT ON GRAPHS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the number of events per user distributed equally in the samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group by 'group' and calculate the number of unique users and total events\n",
    "events_group_per_user = final_df.groupby('group').agg(\n",
    "    num_users=('user_id', 'nunique'), \n",
    "    total_events=('event_dt', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate the average number of events per user\n",
    "events_group_per_user['average_events_per_user'] = events_group_per_user['total_events'] / events_group_per_user['num_users']\n",
    "\n",
    "\n",
    "events_group_per_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the relative frequency of each event within each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'group' and count the value occurrences of 'event_name', normalize to get proportions\n",
    "event_group = final_df.groupby('group')['event_name'].value_counts(normalize=True).reset_index(name='share')\n",
    "event_group['share'] = (event_group['share'] * 100).round(2)\n",
    "\n",
    "event_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"event_name\", y=\"share\", hue=\"group\", data=event_group).set_title(\"Event Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that the number of events per user distributed equally in the samples. Now we will check for users who have been assigned to multiple groups in an A/B test,  count the number of users who are present in exactly one group within 'final_df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby([\"user_id\"])[\"group\"].nunique().reset_index().query(\"group>1\").shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby([\"user_id\"])[\"group\"].nunique().reset_index().query(\"group==1\").shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is the number of events distributed by days?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['event_date']= final_df['event_dt'].dt.date\n",
    "days = final_df.groupby(['event_date']).agg({'user_id':'nunique', 'event_dt':'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Number of events distribution among days')\n",
    "sns.lineplot(data=days, x='event_date', y='event_dt', label='Events')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(days.event_date, rotation=90)\n",
    "plt.ylabel('Events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMMENT ON GRAPH**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['event_date']] = final_df['event_dt'].dt.date\n",
    "days = final_df.groupby(['event_date', 'group']).agg({'user_id':'nunique', 'event_dt':'count'}).reset_index()\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title('Number of events distribution among days')\n",
    "sns.lineplot(data=days, x='event_date', y='event_dt', hue=\"group\")\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(days.event_date, rotation=90)\n",
    "plt.ylabel('Events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of events per test group is very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the A/B test results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can you tell about the A/A test results?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = final_df.groupby('group').agg({'user_id':'nunique'})\n",
    "aa['pct'] = (aa['user_id'] / final_df['user_id'].nunique() * 100).round(2)\n",
    "aa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of users in both groups doesn't vary by more than 1%, as required for a successful A/A test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha = 0.5 / 5\n",
    "pvalue = proportions_ztest(\n",
    "    final_df.query('group == \"A\"')['user_id'].nunique(), \n",
    "    final_df['user_id'].nunique(), value = 0.50)[1]\n",
    "\n",
    "print('\\np-value: {}'.format(pvalue))\n",
    "if pvalue >= alpha: \n",
    "    print('Fail to reject H0: there is not significant difference between groups')\n",
    "else:\n",
    "    print('Reject H0: there is a statistically significant difference between the groups.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the z-criterion to check the statistical difference between the proportions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table to summarize unique user counts for each event by group\n",
    "pivot = final_df.pivot_table(index='event_name', values='user_id', columns='group', aggfunc='nunique').reset_index()\n",
    "\n",
    "# Calculate the conversion percentages for groups A and B\n",
    "pivot['conversion_pct_A'] = ((pivot['A'] / final_df[final_df['group'] == 'A']['user_id'].nunique()) * 100).round(2)\n",
    "pivot['conversion_pct_B'] = ((pivot['B'] / final_df[final_df['group'] == 'B']['user_id'].nunique()) * 100).round(2)\n",
    "\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H0: There is no statistically significant difference between the groups.\n",
    "\n",
    "H1: There is a statistically significant difference between the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hypothesis(group1, group2, event, alpha):\n",
    "    # Extract the number of users who performed the event in each group\n",
    "    successes1 = pivot[pivot['event_name'] == event][group1].iloc[0]\n",
    "    successes2 = pivot[pivot['event_name'] == event][group2].iloc[0]\n",
    "    \n",
    "    # Extract the total number of unique users in each group\n",
    "    trials1 = final_df[final_df['group'] == group1]['user_id'].nunique()\n",
    "    trials2 = final_df[final_df['group'] == group2]['user_id'].nunique()\n",
    "    \n",
    "    # Calculate the proportions of users who performed the event in each group\n",
    "    p1 = successes1 / trials1\n",
    "    p2 = successes2 / trials2\n",
    "    \n",
    "    # Calculate the combined proportion for both groups\n",
    "    p_combined = (successes1 + successes2) / (trials1 + trials2)\n",
    "    \n",
    "    # Calculate the difference between the two proportions\n",
    "    difference = p1 - p2\n",
    "    \n",
    "    # Calculate the z-value for the difference in proportions\n",
    "    z_value = difference / math.sqrt(p_combined * (1 - p_combined) * (1 / trials1 + 1 / trials2))\n",
    "    \n",
    "    # Get the cumulative distribution function of the standard normal distribution\n",
    "    distr = st.norm(0, 1)\n",
    "    \n",
    "    # Calculate the two-tailed p-value from the z-value\n",
    "    p_value = (1 - distr.cdf(abs(z_value))) * 2\n",
    "    \n",
    "    # Print the p-value and the conclusion of the hypothesis test\n",
    "    print(f'Event: {event}, p-value: {p_value}')\n",
    "    if p_value < alpha:\n",
    "        print(f'Reject H0 for {event} between groups {group1} and {group2}')\n",
    "    else:\n",
    "        print(f'Fail to reject H0 for {event} between groups {group1} and {group2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we carried out 4 statistical hypothesis tests, with statistical significance level of 0.05., the probability of making at least one Type I error (false positive) increases when making comparisons with the same data.  We'll use the Bonferroni procedure to adjust the significance level (alpaha) to account for the number os tests being perfomed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each event and test the hypothesis\n",
    "for event in pivot['event_name'].unique():\n",
    "    check_hypothesis('A', 'B', event, 0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we carried out 4 statistical hypothesis tests, with statistical significance level of 0.05., the probability of making at least one Type I error (false positive) increases when making comparisons with the same data.  We'll use the Bonferroni procedure to adjust the significance level (alpaha) to account for the number os tests being perfomed. We are performing 4 tests and want to maintain an overall significance level of 0.05, the Bonferroni correction sets the significance level for each individual test to 0.05/4=0.0125\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pivot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m bonferroni_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpivot\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m      3\u001b[0m     check_hypothesis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m, event, bonferroni_alpha)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pivot' is not defined"
     ]
    }
   ],
   "source": [
    "bonferroni_alpha = 0.05 / 4\n",
    "for event in pivot['event_name'].unique():\n",
    "    check_hypothesis('A', 'B', event, bonferroni_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate over each unique event\n",
    "for event in pivot['event_name'].unique():\n",
    "    check_hypothesis('A', 'B', event, bonferroni_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conlusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
